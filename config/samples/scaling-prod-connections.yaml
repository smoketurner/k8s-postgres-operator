# Production cluster with connection-based reader auto-scaling
# Scales read replicas based on active PostgreSQL connections
#
# KEDA Resources Created:
# - ScaledObject: PostgreSQL trigger with connection count query
# - TriggerAuthentication: References cluster credentials secret
#
# Requirements:
# - KEDA installed
# - Cluster credentials secret must include 'connection-string' key
#
# Test Scenario:
# 1. Apply this manifest
# 2. Wait for 3 replicas to be ready
# 3. Open many concurrent connections:
#    for i in $(seq 1 200); do
#      psql "host=prod-conn-db-repl.default.svc port=5432 user=postgres" -c "SELECT pg_sleep(300)" &
#    done
# 4. Monitor scaling: kubectl get scaledobject prod-conn-db-readers -w
# 5. Verify replicas scale up as connections exceed 50 per replica
# 6. Close connections and verify scale-down
apiVersion: postgres-operator.smoketurner.com/v1alpha1
kind: PostgresCluster
metadata:
  name: prod-conn-db
  namespace: default
  labels:
    environment: production
    team: platform
spec:
  version: "16"
  replicas: 3
  storage:
    size: 50Gi
    storageClass: fast-ssd
  resources:
    requests:
      cpu: "1"
      memory: "2Gi"
    limits:
      cpu: "2"
      memory: "4Gi"
  postgresqlParams:
    max_connections: "500"  # Higher limit for connection-based scaling
    shared_buffers: "512MB"
  tls:
    enabled: true
    issuerRef:
      name: letsencrypt-prod
      kind: ClusterIssuer
  pgbouncer:
    enabled: true
    replicas: 2
    poolMode: session      # Session mode to track actual connections
    maxDbConnections: 100
    maxClientConn: 5000
    enableReplicaPooler: true
  # Connection-based auto-scaling
  scaling:
    minReplicas: 3
    maxReplicas: 15
    metrics:
      connections:
        targetPerReplica: 50   # Scale up when active connections > 50 per replica
    replicationLagThreshold: 1m  # Allow slightly more lag for read-heavy workloads
